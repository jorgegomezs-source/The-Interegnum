<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title> Will the AI Industry Keep the Empire Running? (2026)  | TheInterregnum</title>
    <meta
      name="description"
      content="The AI Mirage: Can Technological Hype Sustain a Declining Empire? "
    />
    <meta name="author" content="Jorge Gómez Seitz" />
    <meta name="date" content="2026-01-25" />

    <!-- Bootstrap CSS -->
    <link
      href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.8/dist/css/bootstrap.min.css"
      rel="stylesheet"
    />
    <!-- Main CSS -->
    <link rel="stylesheet" href="./assets/css/main.css" />

    <!-- Estilos para página de artículo -->
    <style>
      .article-page__hero {
        background: linear-gradient(135deg, #1a5490 0%, #2d5a3d 100%);
        color: white;
        padding: 60px 20px;
        margin-bottom: 40px;
      }

      .article-page__meta {
        display: flex;
        gap: 15px;
        margin-bottom: 20px;
        font-size: 14px;
        flex-wrap: wrap;
      }

      .article-page__category {
        background: rgba(255, 255, 255, 0.2);
        padding: 5px 12px;
        border-radius: 20px;
        font-size: 12px;
        font-weight: bold;
        text-transform: uppercase;
      }

      .article-page__category--economics {
        background: rgba(26, 84, 144, 0.9);
      }

      .article-page__category--geopolitics {
        background: rgba(45, 90, 61, 0.9);
      }

      .article-page__category--trade {
        background: rgba(194, 160, 64, 0.9);
      }

      .article-page__category--finance {
        background: rgba(92, 61, 61, 0.9);
      }

      .article-page__title {
        font-size: 48px;
        font-weight: bold;
        margin-bottom: 20px;
        line-height: 1.2;
      }

      .article-page__subtitle {
        font-size: 20px;
        opacity: 0.95;
        margin-bottom: 30px;
      }

      .article-page__author-info {
        display: flex;
        gap: 20px;
        font-size: 14px;
        flex-wrap: wrap;
      }

      .article-page__image-section {
        padding: 40px 20px;
        background: #f8f9fa;
      }

      .article-page__featured-image {
        width: 100%;
        height: auto;
        border-radius: 8px;
        box-shadow: 0 4px 12px rgba(0, 0, 0, 0.1);
      }

      .article-page__image-caption {
        text-align: center;
        color: #666;
        font-size: 14px;
        margin-top: 15px;
        font-style: italic;
      }

      .article-page__content {
        padding: 60px 20px;
      }

      .article-page__body {
        line-height: 1.8;
        color: #333;
        font-size: 16px;
      }

      .article-page__body h2 {
        font-size: 28px;
        font-weight: bold;
        margin-top: 40px;
        margin-bottom: 20px;
        color: #1a5490;
      }

      .article-page__body h3 {
        font-size: 22px;
        font-weight: 600;
        margin-top: 30px;
        margin-bottom: 15px;
        color: #2d5a3d;
      }

      .article-page__body p {
        margin-bottom: 15px;
      }

      .article-page__body ul,
      .article-page__body ol {
        margin-left: 20px;
        margin-bottom: 20px;
      }

      .article-page__body li {
        margin-bottom: 10px;
      }

      .article-page__quote {
        border-left: 4px solid #1a5490;
        padding-left: 20px;
        margin: 30px 0;
        font-size: 18px;
        font-style: italic;
        color: #555;
        background: #f0f4f8;
        padding: 20px;
        padding-left: 20px;
        border-radius: 4px;
      }

      .article-page__highlight {
        background: #fff3cd;
        padding: 20px;
        border-left: 4px solid #ffc107;
        border-radius: 4px;
        margin: 20px 0;
      }

      .article-page__tags {
        display: flex;
        gap: 10px;
        margin-top: 30px;
        flex-wrap: wrap;
      }

      .article-page__tag {
        background: #e9ecef;
        padding: 8px 15px;
        border-radius: 20px;
        font-size: 12px;
        color: #666;
      }

      .article-page__cta {
        background: linear-gradient(135deg, #1a5490 0%, #2d5a3d 100%);
        color: white;
        padding: 40px;
        border-radius: 8px;
        text-align: center;
        margin-top: 50px;
      }

      .article-page__cta p {
        margin-bottom: 20px;
      }

      .article-page__navigation {
        margin-top: 40px;
        padding-top: 40px;
        border-top: 1px solid #ddd;
      }

      .article-page__navigation a {
        display: inline-block;
        margin-bottom: 20px;
      }

      @media (max-width: 768px) {
        .article-page__hero {
          padding: 40px 20px;
        }

        .article-page__title {
          font-size: 32px;
        }

        .article-page__subtitle {
          font-size: 18px;
        }

        .article-page__content {
          padding: 40px 20px;
        }

        .article-page__body h2 {
          font-size: 22px;
        }

        .article-page__cta {
          padding: 30px 20px;
        }
      }
    </style>
  </head>

  <body>
    <!-- HEADER/NAVBAR -->
    <header class="header">
      <nav class="navbar navbar-expand-lg header__navbar">
        <div class="container">
          <a class="navbar-brand header__brand" href="index.html">
            <span class="header__brand-text">TheInterregnum</span>
          </a>
          <button
            class="navbar-toggler"
            type="button"
            data-bs-toggle="collapse"
            data-bs-target="#navbarNav"
            aria-controls="navbarNav"
            aria-expanded="false"
            aria-label="Toggle navigation"
          >
            <span class="navbar-toggler-icon"></span>
          </button>
          <div class="collapse navbar-collapse" id="navbarNav">
            <ul class="navbar-nav ms-auto">
              <li class="nav-item">
                <a class="nav-link header__menu-link" href="index.html#home"
                  >Home</a
                >
              </li>
              <li class="nav-item">
                <a
                  class="nav-link header__menu-link"
                  href="index.html#categories"
                  >Categories</a
                >
              </li>
              <li class="nav-item">
                <a class="nav-link header__menu-link" href="index.html#articles"
                  >Articles</a
                >
              </li>
              <li class="nav-item">
                <a
                  class="nav-link header__menu-link"
                  href="#newsletter"
                  data-bs-toggle="modal"
                  data-bs-target="#newsletterModal"
                >
                  Newsletter
                </a>
              </li>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- CONTENIDO DEL ARTÍCULO -->
    <main class="article-page">
      <!-- Hero del artículo -->
      <section class="article-page__hero">
        <div class="container">
          <div class="row">
            <div class="col-lg-8 offset-lg-2">
              <div class="article-page__meta">
                <span
                  class="article-page__category article-page__category--economics"
                >
                  Economics
                </span>
                <span class="article-page__date">January 25, 2026</span>
              </div>
              <h1 class="article-page__title">
                Will the AI Industry Keep the Empire Running? (2026)
              </h1>
              <p class="article-page__subtitle">
                The AI Mirage: Can Technological Hype Sustain a Declining Empire?
              </p>
              <div class="article-page__author-info">
                <span class="article-page__author-name"
                  >By Jorge Gómez Seitz</span
                >
                <span class="article-page__reading-time"
                  >Reading time: 8 min</span
                >
              </div>
            </div>
          </div>
        </div>
      </section>

      <!-- Imagen destacada -->
      <section class="article-page__image-section">
        <div class="container">
          <div class="row">
            <div class="col-lg-8 offset-lg-2">
              <img
                src="./assets/img/data_center.jpg"
                alt="Global Economic Trends 2026"
                class="article-page__featured-image"
              />
              <p class="article-page__image-caption">
                A Critical Examination of AI's Compensatory Promise—How Technological Hype Sustains Narratives of Hegemony Amidst Systemic Decline
              </p>
            </div>
          </div>
        </div>
      </section>

      <!-- Contenido principal -->
      <section class="article-page__content">
        <div class="container">
          <div class="row">
            <div class="col-lg-8 offset-lg-2">
              <article class="article-page__body">
                <h1>Will the AI Industry Keep the Empire Running? (2026)</h1>

<p><strong>Techno-Hype and Imperial Decline</strong></p>

<p>The question assumes what remains genuinely unproven. Across Washington, Wall Street, and the technology press, artificial intelligence has been elevated to the status of revolutionary force—capable of restoring American economic dynamism, maintaining military supremacy, and validating the equity valuations that sustain financialized capitalism. The claims are familiar: exponential capability growth, imminent artificial general intelligence, productivity surges that will offset demographic decline and debt overhang, decisive battlefield advantage against peer competitors. The repetition has achieved what repetition achieves—credibility through ubiquity rather than evidence through demonstration. This is not analysis but mobilization, the construction of narrative necessity for investment flows that might otherwise seek more productive destinations.</p>

<p>The purpose here is not to dismiss artificial intelligence as technological artifact. The systems currently deployed—large language models, multimodal generators, recommendation engines, pattern recognition tools—represent genuine advances in statistical modeling and computational scale. They perform specific tasks with proficiency that exceeds prior capability and, in certain domains, human performance. The question is whether this proficiency constitutes the transformation claimed, whether the industry structured around its development can sustain the economic and geopolitical weight assigned to it, and whether the American state and corporate apparatus can convert present advantage into durable hegemony. The historical record suggests caution: previous technological revolutions—railway, electricity, computing—produced their transformative effects through decades of institutional reconstruction, not through the speculative cycles that characterize contemporary AI development.</p>

<p>The American empire in 2026 confronts a structural dilemma. Its productive base has eroded through decades of financialization and offshore relocation. Its military advantage narrows against peer competitors with industrial capacity and technological sophistication that approximate or exceed its own in specific domains. Its ideological appeal, never robust outside Western core populations, has deteriorated through evident hypocrisy and material failure. Into this gap, AI has been inserted as compensatory promise: the restoration of American leadership through superior intelligence, the maintenance of military edge through algorithmic warfare, the revitalization of stagnant productivity through automated labor. The promise serves immediate functions—justifying investment, disciplining labor, directing state subsidy—but its correspondence to achievable reality remains uncertain.</p>

<h2>The Propaganda Apparatus: Confusing Narrative with Substance</h2>

<p>The contemporary AI discourse operates as closed ideological system. Corporate executives, venture capitalists, technology journalists, and policy elites circulate claims that reinforce each other without external validation. OpenAI's Sam Altman speaks of trillions in required investment to achieve artificial general intelligence; the statement is reported as news rather than fundraising pitch. Google's Sundar Pichai describes AI as more profound than fire or electricity; the comparison is analyzed as strategic positioning rather than vacuous hyperbole. Military officials warn of falling behind Chinese AI capabilities; the assessment is accepted without examination of what "capabilities" means in contexts where data, compute, and application differ fundamentally.</p>

<p>This apparatus reproduces patterns familiar from previous technological bubbles. The railway mania of the 1840s, the dot-com exuberance of the 1990s, the blockchain speculation of the 2010s—all featured similar dynamics: narrative convergence around transformative potential, suspension of normal valuation criteria, identification of skeptics with reaction or incomprehension, subsequent collapse when material constraints assert themselves. The AI cycle differs in scale and institutional embedding: the sums involved exceed prior bubbles, the technology has achieved sufficient functionality to generate genuine applications, and state actors have invested strategic priority in ways that prolong subsidy and postpone reckoning. But the underlying structure—confusion of narrative momentum with productive capability—persists.</p>

<p>The specific mechanisms of confusion merit examination. Financial valuation in the AI sector has decoupled from revenue, let alone profit. OpenAI, Anthropic, and comparable entities operate at enormous losses sustained by capital injections from Microsoft, Google, Amazon, and venture funds anticipating eventual monopoly returns. The valuation logic assumes winner-take-all dynamics: present losses are justified by future market dominance that will enable extraction from users dependent on irreplaceable services. Whether this dominance is achievable—whether network effects in AI are as durable as in search or social media, whether open-source alternatives can replicate functionality without comparable investment—remains empirically undetermined. The valuations proceed as if the question were settled.</p>

<p>The productivity claims similarly suspend critical examination. Studies of AI implementation in coding, customer service, and content generation show measurable gains in specific tasks, offset by quality degradation, increased supervision requirements, and unanticipated error modes. The aggregate productivity statistics for the American economy in 2023-2025 do not demonstrate the acceleration promised; growth remains sluggish, investment weak, labor force participation constrained by demographic and social factors that AI does not address. The gap between promised and observed transformation is bridged by projection: the benefits are coming, require more investment, more data, more compute, more time. The structure of justification is unfalsifiable.</p>

<p>The geopolitical claims operate with comparable looseness. American AI supremacy is asserted as foundation of continued hegemony, Chinese AI development as existential threat requiring containment. The actual landscape is more differentiated: Chinese models (DeepSeek, Qwen, Ernie) achieve competitive performance in specific domains, often with greater computational efficiency due to export control evasion and algorithmic innovation; American advantages in semiconductor access and foundational research are real but narrowing; the concept of "supremacy" itself dissolves upon examination of how AI capabilities translate into economic or military effect. The discourse proceeds through national aggregation—American AI versus Chinese AI—that obscures corporate competition, open-source dispersion, and the fundamental commodification of techniques that diffuse rapidly across borders.</p>

<h2>Material Realities: Investment, Infrastructure, and Interdependency</h2>

<p>Beneath the narrative apparatus, the AI industry exhibits material characteristics that constrain its transformative potential. The first is extraordinary capital intensity. Training frontier models requires expenditures measured in billions of dollars for compute, energy, and specialized labor. Inference at scale—actually operating the systems for users—consumes resources that scale with adoption, contrary to software economics where marginal cost approaches zero. The result is structural dependence on continued investment flows and sustained operational subsidy. The industry has not achieved the self-sustaining profitability that would justify its valuations; it remains, in essence, a bet on future monopoly pricing power that regulatory, competitive, and technical factors may prevent from materializing.</p>

<p>The infrastructure requirements create additional vulnerabilities. The specialized semiconductors that enable efficient AI computation—primarily NVIDIA's GPUs and Google's TPUs—are manufactured through supply chains concentrated in East Asia, with final fabrication dependent on Taiwan Semiconductor Manufacturing Company. American export controls, designed to retard Chinese AI development, have accelerated Chinese efforts at import substitution and alternative architectural approaches while disrupting the global division of labor that enabled American corporate dominance. The controls have not prevented Chinese capability advancement; they have imposed costs on American companies denied access to Chinese markets and revenue, and they have stimulated precisely the autarkic development they sought to forestall. The interdependency that American policy assumes as lever proves simultaneously as constraint.</p>

<p>Energy consumption constitutes a further material limit. Training and operating large models requires electrical generation at scales that strain grid capacity and conflict with decarbonization commitments. Data center construction in the American South and West has encountered local opposition, regulatory delay, and insufficient infrastructure. The industry responds with promises of nuclear small modular reactors, enhanced geothermal, and other speculative solutions that will not achieve scale within the relevant timeframe. The result is competition for finite energy resources with other industrial and residential users, and prospective constraint on expansion that the growth projections do not incorporate.</p>

<p>Paradoxically, this energy hunger may become AI's most tangible industrial legacy. The state, compelled to guarantee power for a "strategic" industry, could be forced into a belated, large-scale energy infrastructure program. This creates a potential feedback loop: AI justifies state-led energy investment, which in turn creates a material base (advanced nuclear, grid modernization) that benefits broader, non-AI industrial policy. The hype, in this view, becomes a politically viable cover for the very kind of long-term planning and public investment the financialized state has abandoned. Whether this spillover effect materializes, or whether the energy demand simply triggers rationing and conflict, is a central political question embedded in the technological trajectory.</p>

<p>The labor requirements of AI development, contrary to automation mythology, are substantial and specialized. The systems require data annotation, reinforcement learning from human feedback, error correction, and continuous adjustment that employ hundreds of thousands of workers—often in conditions of precarious employment and psychological stress. The "intelligence" of the systems is substantially outsourced human judgment, aggregated and statisticalized. The industry depends upon global labor arbitrage: American and European researchers design architectures, Chinese and Indian engineers implement systems, Kenyan and Filipino workers provide the judgment that shapes behavior. This division is not stable; it generates its own contradictions around wage pressure, skill transfer, and the political vulnerabilities of concentrated exploitation.</p>

<p>The technological interdependency between supposed rivals undermines the geopolitical framing. American AI research depends upon Chinese graduate students and researchers; Chinese AI development depends upon American-designed semiconductors, however obtained; both depend upon global supply chains for materials, manufacturing, and energy that no single nation controls. The decoupling that strategic competition requires is technically infeasible for the industry as presently structured, and economically destructive for the American corporations that would lose market access and revenue streams. The result is partial decoupling—controls on specific technologies, restrictions on particular transactions—that generates friction without achieving separation, cost without strategic benefit.</p>

<h2>The Profit Problem: Valuation without Revenue</h2>

<p>The financial structure of the AI industry presents a distinctive problem. The major corporate players—Microsoft, Google, Amazon, Meta—have invested tens of billions in AI development and infrastructure. These investments are justified to shareholders through growth projections and competitive necessity rather than present returns. The AI divisions operate as cost centers sustained by profits from other business lines: cloud computing, advertising, software licensing. The structure resembles industrial diversification rather than productive transformation: capital allocated to maintain position in anticipated future markets, not to revolutionize present operations.</p>

<p>The pure-play AI entities—OpenAI, Anthropic, and their competitors—exhibit more extreme financial characteristics. They generate revenue from API access and subscription services, but this revenue covers a fraction of operational costs. Their valuations depend upon continued capital injection from strategic investors—primarily the major technology corporations—who accept losses for access to technology, talent, and market position. The arrangement is sustainable only as long as the strategic investors maintain commitment, which depends upon their own financial performance and competitive assessment. A deterioration in cloud computing margins, a shift in investor sentiment, or a technical plateau in capability improvement could rapidly contract available funding.</p>

<p>The absence of clear paths to profitability is not accidental. The business models assume eventual monopoly or oligopoly pricing power that regulatory, competitive, and technical factors may prevent. Open-source models—Llama, Mistral, DeepSeek—replicate significant functionality without comparable investment, constraining pricing power for proprietary alternatives. Regulatory pressure in Europe and potentially America challenges the data aggregation and platform dominance that would enable extraction. The technology itself—probabilistic, error-prone, context-dependent—may prove unsuitable for high-value applications where reliability is essential, limiting addressable market.</p>

<p>The macroeconomic implications are substantial. The AI investment boom has sustained technology sector valuations and equity market indices that would otherwise reflect broader economic stagnation. The wealth effects—capital gains for shareholders, compensation for employees—have supported consumption in geographic concentrations (San Francisco, Seattle, New York) that mask general conditions. A contraction in AI investment, whether through technical plateau, competitive displacement, or funding exhaustion, would transmit rapidly through financial markets and regional economies. The industry has become systemically significant not through productive contribution but through financial embedding.</p>

<h2>Realistic Capabilities: The Next Decade</h2>

<p>Assessment of what AI can realistically achieve requires separation of demonstrated capability from aspirational projection. Current systems excel at pattern recognition in bounded domains: language generation within stylistic conventions, image synthesis from textual description, code completion for common patterns, recommendation based on behavioral similarity. These capabilities are genuine and economically valuable for specific applications. They do not constitute general intelligence, autonomous reasoning, or creative innovation in senses that would transform labor markets or strategic competition.</p>

<p>The trajectory of improvement is uncertain. Scaling—larger models, more data, more compute—has produced consistent gains but with diminishing returns and escalating costs. Architectural innovations (mixture-of-experts, retrieval augmentation, multimodal integration) extend capability without resolving fundamental limitations: hallucination, reasoning failure, context limitation, brittleness outside training distribution. Whether additional scaling or novel architectures can overcome these limitations is empirically unknown; the assumption that they will constitutes the primary basis for industry valuation.</p>

<p>A conservative projection for the next decade would include: continued improvement in specialized applications with gradual expansion of domain coverage; incremental automation of routine cognitive tasks in law, finance, administration, and media production; persistent requirement for human oversight and correction; limited penetration in high-stakes domains (medicine, engineering, military command) where error costs exceed efficiency gains; gradual commodification of base capabilities and consolidation of value capture in data aggregation and platform control. This trajectory implies significant but not revolutionary economic impact, competitive dynamics shaped by implementation and distribution rather than fundamental capability, and continued dependence on human labor for judgment, innovation, and social coordination.</p>

<p>More ambitious projections—artificial general intelligence, autonomous scientific discovery, comprehensive automation—require assumptions about technical breakthroughs that cannot be scheduled or guaranteed. The history of AI research includes multiple periods of exaggerated expectation followed by disillusion; the present cycle may prove comparable. The appropriate analytical stance is agnosticism about ultimate limits combined with skepticism about near-term transformation. The industry has incentives to promote ambitious projections; the interests of accurate assessment diverge from these incentives.</p>

<h2>AI in Class Struggle: Rhetoric and Reality</h2>

<p>The deployment of AI operates as instrument of class power in ways that transcend its technical capabilities. The rhetorical function is primary: AI as threat to employment disciplines workers who might otherwise demand wage increases or improved conditions; AI as productivity justification enables intensification of work pace and surveillance; AI as skill requirement stratifies labor markets and legitimizes credential exclusion. The actual technology matters less than the narrative of its imminence, which shapes bargaining power and organizational possibility before any substitution occurs.</p>

<p>The empirical record of labor displacement is more nuanced than the rhetoric suggests. Automation through AI has proceeded selectively: customer service chatbots supplement rather than replace human agents; coding assistants increase output for skilled programmers rather than eliminate them; content generation tools expand volume for media production rather than substitute creative labor. The pattern is augmentation and intensification more than replacement, with effects varying by skill level, sector, and regulatory environment. The aggregate employment impact through 2025 has been modest compared to structural factors (demography, trade, macroeconomic policy) that receive less analytical attention.</p>

<p>The distributional effects are clearer and more significant. AI development concentrates returns among technology corporations, their investors, and highly specialized technical labor. The broader productivity gains, where realized, accrue primarily to capital rather than labor. The technology extends patterns of inequality established through prior digitalization: winner-take-all dynamics in platform markets, polarization between elite and routine employment, geographic concentration in metropolitan centers with advanced infrastructure and education. AI intensifies these patterns without fundamentally altering their structure.</p>

<p>The organizational response from labor has been uneven. Some sectors (screenwriting, visual arts, journalism) have mobilized against AI displacement through contractual restriction and regulatory advocacy. Others (software engineering, customer service, logistics) have experienced more individualized adaptation. The potential for collective bargaining around AI deployment—transparency requirements, retraining obligations, productivity sharing—remains largely unrealized due to union weakness and legal frameworks that privilege employer discretion. The rhetorical construction of AI as inevitable natural force, rather than political choice, constrains organizational possibility.</p>

<p>This rhetorical function extends beyond the disciplining of labor to the co-option of the Professional-Managerial Class (PMC). For strata whose social purpose has been eroded by financialization and deindustrialization—researchers, engineers, mid-level managers, policy analysts—AI hype offers a renewed sense of historical agency and elite identity. The project of "building the future" or "solving intelligence" provides a mission that mitigates their own potential disaffection with a stagnant system, channeling their energies into a techno-solutionist paradigm that leaves underlying power relations undisturbed. The PMC becomes both architect and captive of the narrative, its social identity invested in the perpetuation of the hype cycle.</p>

<p>The strategic implication is that AI functions less as autonomous technological transformation than as terrain of contestation. Its development and deployment are shaped by power relations that could be altered through political mobilization. The present trajectory—concentration of benefit, intensification of work, erosion of security—is not technically determined but institutionally constructed. Alternative arrangements are conceivable: public ownership of foundational models, democratic governance of data, productivity sharing through reduced hours rather than labor displacement, investment in care and maintenance rather than automation of the automatable. The absence of these alternatives from mainstream discourse reflects political defeat rather than technical necessity.</p>

<h2>Military AI: Pandora's Box or Paper Tiger?</h2>

<p>The military application of AI presents distinctive dangers that merit specific examination. The American defense establishment has invested substantially in AI for intelligence analysis, autonomous systems, command decision support, and cyber operations. The justification is competitive necessity: Chinese military modernization, Russian battlefield innovation, the imperative of maintaining technological edge. The actual capabilities achieved and their strategic utility require critical assessment.</p>

<p>The most immediately deployed applications—image recognition for target identification, pattern analysis for intelligence fusion, predictive maintenance for logistics—extend existing military functions without transforming them. The promise of more radical applications—autonomous weapons systems operating without human intervention, AI-assisted command decisions at operational tempo exceeding human cognition, cyber weapons that adapt and persist—remains largely aspirational. The technical challenges of reliable operation in contested, degraded environments are substantial; the organizational challenges of integrating AI into command structures with established doctrine and career incentives are equally significant.</p>

<p>The strategic logic of military AI is destabilizing in ways that parallel nuclear weapons but without equivalent stabilizing mechanisms. Competitive pressure drives rapid deployment of inadequately tested systems. The fog of war—uncertainty about adversary capabilities, intentions, and system behavior—is compounded by opacity of AI decision-making. The compression of decision timelines that AI enables reduces opportunity for human judgment and escalation control. The diffusion of enabling technology—commercial drones, open-source software, widely available sensors—erodes the monopoly advantages that justified American investment.</p>

<p>The specific risks include: accidental engagement through autonomous system misidentification; escalation through competitive algorithmic response; strategic surprise from adversary capabilities that intelligence failed to anticipate; collapse of deterrence through overconfidence in AI-enabled advantage. These risks are recognized in military discourse but addressed primarily through technical safeguards rather than structural restraint. The institutional momentum toward deployment overwhelms precautionary consideration.</p>

<p>The comparison with nuclear weapons is instructive. Nuclear technology presented similar revolutionary promise and existential risk; its management required decades of negotiation, institutional construction, and doctrinal development that remains incomplete. AI lacks even the rudimentary arms control frameworks that constrain nuclear competition. The technology diffuses more easily, its applications are less distinguishable between civilian and military, its strategic effects are less well understood. The Pandora's box metaphor understates the difficulty: the technology is already widely distributed, the lid is open, and the question is whether any constraint remains possible.</p>

<p>The Chinese and Russian military AI programs parallel American development with distinctive emphases. China invests heavily in swarm robotics, quantum communication, and cognitive electronic warfare; Russia emphasizes information operations and battlefield automation. The competitive dynamic—each side's investment justifying the others', each's secrecy preventing confidence-building—resembles earlier arms races with added uncertainty from technological opacity. The prospective stability of mutual AI deterrence is unproven and possibly unachievable.</p>

<p>Beyond operational risk, the funding vortex of military AI is birthing a new structural constituency: the Military-AI-Industrial Complex. A self-reinforcing network of Pentagon offices, defense contractors (traditional and new-tech), university labs, and specialized congressional committees is coalescing around the flow of tens of billions in designated funding. This complex has a structural interest in perpetuating the narrative of a relentless, high-stakes race, as its budget, relevance, and career trajectories depend on it. The technology's actual battlefield utility becomes secondary to its function as a vehicle for resource allocation and institutional renewal within the defense bureaucracy. This ensures that even if specific systems fail or prove destabilizing, the political-economic engine driving their development will prove difficult to dismantle.</p>

<h2>Conclusion: The Limits of Technological Substitution</h2>

<p>The AI industry in 2026 presents a paradox: unprecedented investment and attention alongside uncertain productive contribution and questionable strategic utility. The paradox resolves through recognition that the industry's primary function is not technical but political-economic. It sustains equity valuations, justifies state subsidy, disciplines labor, and mobilizes ideological commitment to American supremacy. Whether it can perform these functions indefinitely, whether the gap between promise and delivery generates destabilizing disillusion, whether competitors achieve sufficient capability to neutralize advantage—these determine the industry's geopolitical significance more than any technical metric.</p>

<p>The American empire's reliance on AI as compensatory promise reflects deeper incapacity. The productive reconstruction that would address trade deficits, infrastructure decay, and social decomposition is institutionally blocked by financial interests and ideological commitment to market allocation. The military modernization that would restore unchallenged supremacy is fiscally constrained and technically competed. The social integration that would restore ideological appeal would require redistribution that ruling classes reject. Into this gap, AI is inserted as deus ex machina: the solution that arrives without political choice, the transformation that requires only investment and patience.</p>

<p>The historical probability is that this insertion fails. Technological innovation does not substitute for political and institutional reconstruction; it requires such reconstruction to achieve transformative effect. The AI industry may persist as significant sector without constituting the revolutionary force claimed, its valuations eventually adjusting to productive reality, its geopolitical significance diminishing as competitors achieve parity, its military applications constrained by strategic risk. The American empire would then confront the conditions it sought to escape: relative decline, internal contradiction, and the necessity of adaptation that ideology and interest have prevented.</p>

<p>The alternative possibility—genuine breakthrough, sustained advantage, transformative productivity—cannot be dismissed on analytical grounds. But its realization would require what the present structure prevents: patient institutional investment, democratic governance of technology, distribution of benefit that maintains social cohesion, strategic restraint that avoids catastrophic conflict. These are political choices, not technical outcomes.</p>

<p>Concretely, this alternative pathway would entail: the public ownership and fiduciary stewardship of foundational model development as critical infrastructure; the governance of training data and model behavior by democratic assemblies, not corporate boards; legal frameworks that redirect productivity gains into shortened working hours and robust social wages rather than layoffs and profit concentration; and international treaties that establish red lines for military AI applications and foster cooperative governance of compute and algorithmic resources as a global commons.</p>

<p>The AI industry as presently constituted embodies their negation. Whether it can be reconstituted to embody their realization determines not only the technology's trajectory but the possibility of navigating imperial decline without catastrophe.</p>
                <p>By Jorge Gómez Seitz</p>

                <h1>References</h1>

<p><em>Organized by Analytical Themes</em></p>

<h2>The Propaganda Apparatus and Techno-Hype</h2>

<p><strong>Claim:</strong> AI discourse operates as closed ideological system where corporate, financial, and policy elites circulate claims that reinforce each other without external validation.</p>

<p><strong>Evgeny Morozov</strong> — Critiques "technological solutionism" and the ideological functions of innovation discourse. See <em>To Save Everything, Click Here: The Folly of Technological Solutionism</em> (2013).</p>

<p><strong>David Noble</strong> — Analyzes how automation ideology serves managerial interests regardless of technical feasibility. See <em>Progress Without People: New Technology, Unemployment, and the Message of Resistance</em> (1995).</p>

<p><strong>Langdon Winner</strong> — Examines the political dimensions of technological artifacts and the "technological imperative" that constrains democratic choice. See <em>Autonomous Technology: Technics-out-of-Control as a Theme in Political Thought</em> (1977) and <em>The Whale and the Reactor: A Search for Limits in an Age of High Technology</em> (1986).</p>

<p><strong>Dan McQuillan</strong> — Analyzes AI as ideological construct and the "resistances" to its deployment. See <em>Resisting AI: An Anti-fascist Approach to Artificial Intelligence</em> (2022).</p>

<p><strong>Edward S. Herman & Noam Chomsky</strong> — The "propaganda model" of media functioning, where elite consensus manufacturing substitutes for critical examination. See <em>Manufacturing Consent: The Political Economy of the Mass Media</em> (1988).</p>

<h2>Material Realities: Investment, Infrastructure, and Interdependency</h2>

<p><strong>Claim:</strong> AI industry exhibits capital intensity, supply chain concentration, energy constraints, and labor dependence that undermine transformative claims.</p>

<p><strong>Kate Crawford</strong> — Documents the material and labor foundations of AI systems, from extraction to data annotation. See <em>Atlas of AI: Power, Politics, and the Planetary Costs of Artificial Intelligence</em> (2021).</p>

<p><strong>Vincent Mosco</strong> — Analyzes the "digital sublime" and the material infrastructure of cloud computing. See <em>Becoming Digital: Toward a Post-Internet Society</em> (2017) and <em>The Cloud: Big Data in a Turbulent World</em> (2014).</p>

<p><strong>Naomi Klein</strong> — Examines how crisis narratives enable corporate restructuring and public subsidy. See <em>The Shock Doctrine: The Rise of Disaster Capitalism</em> (2007).</p>

<p><strong>Michael Hudson</strong> — Analyzes financialization, debt peonage, and the extraction mechanisms of contemporary capitalism. See <em>Killing the Host: How Financial Parasites and Debt Bondage Destroy the Global Economy</em> (2015) and <em>The Destiny of Civilization: Finance Capitalism, Industrial Capitalism or Socialism</em> (2022). His analysis of the FIRE sector and "tribute economy" informs the treatment of AI investment as speculative extraction rather than productive transformation.</p>

<h2>Semiconductor Geopolitics and Supply Chain Vulnerability</h2>

<p><strong>Claim:</strong> AI capability depends upon concentrated supply chains that American export controls disrupt without achieving strategic separation from China.</p>

<p><strong>Chris Miller</strong> — Documents the geopolitical history of semiconductor manufacturing and the Taiwan concentration. See <em>Chip War: The Fight for the World's Most Critical Technology</em> (2022).</p>

<p><strong>Gregory C. Allen</strong> — Analyzes U.S.-China technological competition and the limits of decoupling strategies. See work at Center for Strategic and International Studies on export controls and Chinese response.</p>

<p><strong>Chad P. Bown</strong> — Examines the trade policy dimensions of technological competition and the economic costs of restriction. See analysis at Peterson Institute for International Economics.</p>

<h2>Energy, Infrastructure, and State-Led Investment</h2>

<p><strong>Claim:</strong> AI's energy demands may trigger state-led infrastructure development that spills over into broader industrial policy, or alternatively generate resource conflict.</p>

<p><strong>Brett Christophers</strong> — Analyzes the political economy of energy infrastructure and state-market relations. See <em>The Price is Everything: How Capitalism Came to Colonize the Future</em> (2024) and <em>Rentier Capitalism: Who Owns the Economy, and Who Pays for It?</em> (2020).</p>

<p><strong>Mariana Mazzucato</strong> — Documents the state's foundational role in technological development and the possibilities for mission-oriented industrial policy. See <em>The Entrepreneurial State: Debunking Public vs. Private Sector Myths</em> (2013) and <em>Mission Economy: A Moonshot Guide to Changing Capitalism</em> (2021).</p>

<p><strong>Matteo Pasquinelli</strong> — Examines the "energy unconscious" of machine learning and the material metabolism of AI systems. See "The Labour of Surveillance and Bureaucratized Knowledge" (2019) and <em>The Eye of the Master: A Social History of Artificial Intelligence</em> (2023).</p>

<h2>Financialization and the Profit Problem</h2>

<p><strong>Claim:</strong> AI industry operates through valuation without revenue, sustained by strategic investment rather than profitability, with systemic risk from potential contraction.</p>

<p><strong>Brett Christophers</strong> — Analyzes assetization and the financialization of the economy. See <em>The Price is Everything: How Capitalism Came to Colonize the Future</em> (2024) and <em>Rentier Capitalism: Who Owns the Economy, and Who Pays for It?</em> (2020).</p>

<p><strong>William I. Robinson</strong> — Examines transnational capitalist class formation and the mechanisms of global financial integration. See <em>Global Capitalism and the Crisis of Humanity</em> (2014).</p>

<p><strong>Greta Krippner</strong> — Documents the political construction of financialization and its displacement of productive investment. See <em>Capitalizing on Crisis: The Political Origins of the Rise of Finance</em> (2011).</p>

<p><strong>Michael Hudson</strong> — Distinguishes between industrial and finance capitalism, analyzing how debt overhead and rent extraction prevent productive investment. See <em>Super Imperialism: The Economic Strategy of American Empire</em> (1972, updated 2003) for the historical construction of dollar hegemony and its contemporary contradictions.</p>

<p><strong>Annie McClanahan</strong> — Analyzes "dead pledges" and the culture of debt in contemporary capitalism. See <em>Dead Pledges: Debt, Crisis, and Twenty-First-Century Culture</em> (2016).</p>

<h2>AI Capabilities and Limitations</h2>

<p><strong>Claim:</strong> Current AI exhibits genuine but bounded capabilities; transformative claims depend upon unproven assumptions about scaling and architectural innovation.</p>

<p><strong>Meredith Whittaker</strong> — Analyzes the political economy and labor foundations of AI systems, and the gap between corporate claims and technical reality. See work at AI Now Institute.</p>

<p><strong>Timnit Gebru & Emily M. Bender</strong> — Critique large language model capabilities and the "stochastic parrot" nature of generated text. See "On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?" (2021) and subsequent analysis of AI hype.</p>

<p><strong>Gary Marcus</strong> — Examines the limitations of deep learning and the challenges of achieving robust, generalizable AI. See <em>Rebooting AI: Building Artificial Intelligence We Can Trust</em> (2019, with Ernest Davis).</p>

<p><strong>Emily M. Bender & Alexander Koller</strong> — Analyze the "meaning" problem in language models and the confusion of form with understanding. See "Climbing towards NLU: On Meaning, Form, and Understanding in the Age of Data" (2020).</p>

<h2>AI in Class Struggle: Labor, Distribution, and the PMC</h2>

<p><strong>Claim:</strong> AI functions primarily as instrument of class power through rhetorical threat and work intensification, while simultaneously co-opting the Professional-Managerial Class through mission-driven ideology.</p>

<p><strong>Antonio Casilli</strong> — Documents the "digital labor" that sustains apparent AI automation. See <em>En attendant les robots: Enquête sur le travail du clic</em> (2019; English translation <em>Waiting for Robots: The Hired Hands of Automation</em>).</p>

<p><strong>Nick Dyer-Witheford</strong> — Analyzes the "cyber-proletariat" and digital labor in global capitalism. See <em>Cyber-Proletariat: Global Labour in the Digital Vortex</em> (2015).</p>

<p><strong>Ursula Huws</strong> — Examines the restructuring of labor through digitalization and the "gig economy." See <em>Labor in the Global Digital Economy: The Cybertariat Comes of Age</em> (2014).</p>

<p><strong>Barbara Ehrenreich & John Ehrenreich</strong> — Originated the concept of the "Professional-Managerial Class" and its contradictory position within capitalism. See "The Professional-Managerial Class" (1977) and subsequent analyses of PMC politics.</p>

<p><strong>Catherine Liu</strong> — Examines the PMC's cultural and political role in neoliberalism and its mechanisms of self-reproduction. See <em>Virtue Hoarders: The Case against the Professional Managerial Class</em> (2021).</p>

<p><strong>Michael Hudson</strong> — Analyzes how technological change under financialized capitalism serves rentier interests rather than productivity-sharing. His work on the "tribute economy" and the extraction of surplus through debt and monopoly informs the treatment of AI as instrument of class power.</p>

<h2>Military AI and the Military-AI-Industrial Complex</h2>

<p><strong>Claim:</strong> Military AI applications present destabilizing risks without equivalent stabilizing mechanisms to nuclear arms control, while generating new structural constituencies with interest in perpetual escalation.</p>

<p><strong>Paul Scharre</strong> — Analyzes autonomous weapons and the strategic implications of military AI. See <em>Army of None: Autonomous Weapons and the Future of War</em> (2018).</p>

<p><strong>Stuart Russell</strong> — Examines the existential risks of autonomous weapons and the challenge of meaningful human control. See <em>Human Compatible: Artificial Intelligence and the Problem of Control</em> (2019).</p>

<p><strong>Lethal Autonomous Weapons Pledge and Campaign to Stop Killer Robots</strong> — Documents civil society efforts to restrict autonomous weapons and the resistance of major powers.</p>

<p><strong>Jackie Snow</strong> — Analyzes the "AI arms race" framing and its strategic consequences. See work at MIT Technology Review and subsequent analysis of military AI competition.</p>

<p><strong>Michael Klare</strong> — Examines resource competition and military technology in great power rivalry. See <em>All Hell Breaking Loose: The Pentagon's Perspective on Climate Change</em> (2019) and <em>The Race for What's Left: The Global Scramble for the World's Last Resources</em> (2012).</p>

<p><strong>C. Wright Mills</strong> — The classic analysis of the "military-industrial complex" and its structural role in American political economy. See <em>The Power Elite</em> (1956).</p>

<p><strong>Melvin Kranzberg</strong> — Formulated Kranzberg's Laws of technology, including "Technology is neither good nor bad; nor is it neutral." See "Technology and History: Kranzberg's Laws" (1986).</p>

<h2>Historical Precedents: Bubbles, Revolutions, and Disappointment</h2>

<p><strong>Claim:</strong> AI cycle resembles previous technological bubbles in structure of hype and potential for disillusion.</p>

<p><strong>Carlota Perez</strong> — Analyzes technological revolutions and their financial bubbles, distinguishing between installation and deployment phases. See <em>Technological Revolutions and Financial Capital: The Dynamics of Bubbles and Golden Ages</em> (2002).</p>

<p><strong>David Edgerton</strong> — Critiques "innovation-centric" history and emphasizes the continuity of "old" technologies. See <em>The Shock of the Old: Technology and Global History since 1900</em> (2007).</p>

<p><strong>Jill Lepore</strong> — Examines the "disruption" ideology and its historical amnesia. See "The Disruption Machine: What the Gospel of Innovation Gets Wrong" (2014) in <em>The New Yorker</em>.</p>

<h2>Democratic Alternatives and Political Choice</h2>

<p><strong>Claim:</strong> Alternative arrangements for AI development and governance are conceivable but require political mobilization that present structure prevents.</p>

<p><strong>Nick Srnicek & Alex Williams</strong> — Argue for "accelerationism" and technological repurposing toward post-capitalist ends. See <em>Inventing the Future: Postcapitalism and a World Without Work</em> (2015).</p>

<p><strong>Aaron Bastani</strong> — Proposes "Fully Automated Luxury Communism" as framework for technological abundance under democratic control. See <em>Fully Automated Luxury Communism: A Manifesto</em> (2019).</p>

<p><strong>Erik Olin Wright</strong> — Analyzes "real utopias" and the institutional possibilities for democratic socialist transformation. See <em>Envisioning Real Utopias</em> (2010) and <em>How to Be an Anti-Capitalist in the Twenty-First Century</em> (2019).</p>

<p><strong>Michael Hudson</strong> — Documents historical alternatives to debt-peonage capitalism and the possibilities for public banking and democratic financial control. See <em>...and Forgive Them Their Debts: Lending, Foreclosure and Redemption from Bronze Age Finance to the Jubilee Year</em> (2018).</p>

<h2>Intellectual Tradition and Overall Framing</h2>

<p>The text's overarching framework is most directly informed by:</p>

<p><strong>Immanuel Wallerstein (World-Systems Analysis)</strong> — The concepts of hegemonic cycles, systemic transition, and the structural constraints on core power restoration. See <em>The Modern World-System</em> (4 vols., 1974-2011) and <em>World-Systems Analysis: An Introduction</em> (2004).</p>

<p><strong>Giovanni Arrighi</strong> — The analysis of financialization as symptom of hegemonic decline and the East Asian challenge to Western dominance. See <em>The Long Twentieth Century: Money, Power, and the Origins of Our Times</em> (1994) and <em>Adam Smith in Beijing: Lineages of the Twenty-First Century</em> (2007).</p>

<p><strong>Robert Brenner</strong> — The "long downturn" thesis and the structural crisis of profitability in advanced capitalism. See <em>The Economics of Global Turbulence: The Advanced Capitalist Economies from Long Boom to Long Downturn, 1945-2005</em> (2006).</p>

<p><strong>Wolfgang Streeck</strong> — The analysis of capitalist decomposition and the exhaustion of institutional stabilization. See <em>How Will Capitalism End? Essays on a Failing System</em> (2016) and <em>Buying Time: The Delayed Crisis of Democratic Capitalism</em> (2014).</p>

<p><strong>Michael Hudson</strong> — Synthesizes classical political economy, archaeology, and contemporary finance to analyze the dynamics of debt, empire, and economic polarization. His work on the "tribute economy" of American hegemony, the distinction between industrial and finance capitalism, and the impossibility of reform within financialized structures provides essential grounding for the text's assessment of AI as failed compensatory promise. See <em>Global Fracture: The New International Economic Order</em> (1977, updated 2005) and <em>Trade, Development and Foreign Debt: A History of Theories of Polarization v. Convergence in the World Economy</em> (1992, updated 2009).</p>

<p><strong>David Harvey</strong> — The analysis of "accumulation by dispossession," spatial fixes, and the limits of capitalist expansion. See <em>The New Imperialism</em> (2003), <em>A Brief History of Neoliberalism</em> (2005), and <em>The Enigma of Capital and the Crises of Capitalism</em> (2010).</p>

<p><strong>Herbert Marcuse</strong> — The critique of "technological rationality" as ideology and the possibilities for its transcendence. See <em>One-Dimensional Man: Studies in the Ideology of Advanced Industrial Society</em> (1964).</p>
                  <!-- Tags -->
                </p>

                <div class="article-page__tags">
                  <span class="article-page__tag">economics</span>
                  <span class="article-page__tag">geopolitics</span>
                  <span class="article-page__tag">international-trade</span>
                  <span class="article-page__tag">2026</span>
                </div>

                <!-- Call to action -->
                <div class="article-page__cta">
                  <p>
                    <strong
                      >Want to stay informed about global economic
                      trends?</strong
                    ><br />
                    Subscribe to our newsletter for weekly analysis and insights
                    on international politics and economics.
                  </p>
                  <button
                    class="btn btn-light btn-sm"
                    data-bs-toggle="modal"
                    data-bs-target="#newsletterModal"
                  >
                    Subscribe to Newsletter
                  </button>
                </div>

                <!-- Navigation -->
                <nav class="article-page__navigation">
                  <a
                    href="index.html#articles"
                    class="btn btn-outline-primary btn-sm"
                  >
                    ← Back to Articles
                  </a>
                </nav>
              </article>
            </div>
          </div>
        </div>
      </section>
    </main>

    <!-- FOOTER -->
    <footer class="footer">
      <div class="container">
        <div class="footer__grid">
          <div class="footer__column">
            <h5>TheInterregnum</h5>
            <p>Global politics and economics analysis</p>
          </div>
          <div class="footer__column">
            <h5>Navigation</h5>
            <ul>
              <li><a class="footer__link" href="index.html">Home</a></li>
              <li>
                <a class="footer__link" href="index.html#categories"
                  >Categories</a
                >
              </li>
              <li>
                <a class="footer__link" href="index.html#articles">Articles</a>
              </li>
            </ul>
          </div>
          <div class="footer__column">
            <h5>Categories</h5>
            <ul>
              <li><a class="footer__link" href="#">Geopolitics</a></li>
              <li><a class="footer__link" href="#">Economics</a></li>
              <li><a class="footer__link" href="#">Trade</a></li>
            </ul>
          </div>
          <div class="footer__column">
            <h5>Follow</h5>
            <ul>
              <li><a class="footer__link" href="#">Twitter</a></li>
              <li><a class="footer__link" href="#">LinkedIn</a></li>
              <li><a class="footer__link" href="#">RSS</a></li>
            </ul>
          </div>
        </div>
        <div class="footer__bottom">
          <p>
            &copy; 2026 TheInterregnum. All rights reserved. |
            <a class="footer__link" href="#">Privacy Policy</a> |
            <a class="footer__link" href="#">Terms of Service</a>
          </p>
        </div>
      </div>
    </footer>

    <!-- Newsletter Modal -->
    <div
      class="modal fade"
      id="newsletterModal"
      tabindex="-1"
      aria-labelledby="newsletterModalLabel"
      aria-hidden="true"
    >
      <div class="modal-dialog modal-dialog-centered">
        <div class="modal-content">
          <div class="modal-header">
            <h5 class="modal-title" id="newsletterModalLabel">
              Subscribe to Newsletter
            </h5>
            <button
              type="button"
              class="btn-close"
              data-bs-dismiss="modal"
              aria-label="Close"
            ></button>
          </div>
          <div class="modal-body">
            <form id="newsletterForm" class="newsletter__form">
              <div class="mb-3">
                <label for="emailInput" class="form-label">Email Address</label>
                <input
                  type="email"
                  class="form-control"
                  id="emailInput"
                  placeholder="your@email.com"
                  required
                />
              </div>
              <button type="submit" class="btn btn-primary w-100">
                Subscribe
              </button>
            </form>
          </div>
        </div>
      </div>
    </div>

    <!-- Bootstrap JS -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.8/dist/js/bootstrap.bundle.min.js"></script>
    <!-- Main JS -->
    <script src="./assets/js/main.js"></script>
  </body>
</html>
